// web/src/components/VoiceChatOverlay.jsx
import { useState, useEffect, useCallback, useRef } from "react";
import { TemiBridge } from "../services/temiBridge";
import { callGeminiAPI } from "../utils/geminiAPI";

export default function VoiceChatOverlay({ isOpen, onClose }) {
  const [currentStep, setCurrentStep] = useState("idle");
  const [messages, setMessages] = useState([]);

  const isRecognitionActiveRef = useRef(false);
  const ttsTimeoutRef = useRef(null);
  const listeningTimeoutRef = useRef(null);
  const currentStepRef = useRef("idle");
  const chatContainerRef = useRef(null);

  /**
   * ìŒì„± ì¸ì‹ ì‹œì‘
   */
  const startListening = useCallback(() => {
    console.log("ğŸ¤ [startListening] ì‹œë„");

    if (isRecognitionActiveRef.current) {
      console.log("âš ï¸ [startListening] ì´ë¯¸ ì¸ì‹ ì„¸ì…˜ í™œì„±í™”ë¨, ë¬´ì‹œ");
      return;
    }

    if (currentStepRef.current !== "idle") {
      console.log(
        `âš ï¸ [startListening] í˜„ì¬ ${currentStepRef.current} ë‹¨ê³„, ë¬´ì‹œ`
      );
      return;
    }

    console.log("âœ… [startListening] ìŒì„± ì¸ì‹ ì‹œì‘");

    isRecognitionActiveRef.current = true;
    currentStepRef.current = "listening";
    setCurrentStep("listening");

    try {
      TemiBridge.startSpeechRecognition();

      // âœ… 8ì´ˆ íƒ€ì„ì•„ì›ƒ ì„¤ì •
      if (listeningTimeoutRef.current) {
        clearTimeout(listeningTimeoutRef.current);
      }

      listeningTimeoutRef.current = setTimeout(() => {
        console.log("â° [Timeout] 8ì´ˆ ë™ì•ˆ ìŒì„± ê°ì§€ ì•ˆë¨, ìë™ ì¢…ë£Œ");

        isRecognitionActiveRef.current = false;
        currentStepRef.current = "idle";
        setCurrentStep("idle");

        TemiBridge.stopSpeechRecognition();
        TemiBridge.showToast("ìŒì„±ì´ ê°ì§€ë˜ì§€ ì•Šì•„ ëŒ€í™”ê°€ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤");
      }, 8000);
    } catch (error) {
      console.error("âŒ [startListening] ì‹¤íŒ¨:", error);

      // âœ…âœ…âœ… Temi í™˜ê²½ì—ì„œ "already started" ì—ëŸ¬ëŠ” ë¬´ì‹œ
      if (
        window.Temi &&
        error.message &&
        error.message.includes("already started")
      ) {
        console.warn("âš ï¸ Temi í™˜ê²½: ì´ë¯¸ ì‹œì‘ë¨ ì—ëŸ¬ ë¬´ì‹œ");
        return;
      }

      isRecognitionActiveRef.current = false;
      currentStepRef.current = "idle";
      setCurrentStep("idle");

      if (listeningTimeoutRef.current) {
        clearTimeout(listeningTimeoutRef.current);
      }
    }
  }, []);

  /**
   * ì˜¤ë²„ë ˆì´ ì—´ë¦´ ë•Œ ì´ˆê¸°í™” + ì²« ë“£ê¸° ì‹œì‘
   */
  useEffect(() => {
    if (isOpen) {
      console.log("ğŸŸ¢ [Overlay] ì˜¤í”ˆ - ì´ˆê¸°í™” ë° ë“£ê¸° ì‹œì‘");

      setMessages([]);
      setCurrentStep("idle");

      setTimeout(() => {
        startListening();
      }, 300);
    } else {
      console.log("ğŸ”´ [Overlay] ë‹«í˜ - ì •ë¦¬");

      if (ttsTimeoutRef.current) {
        clearTimeout(ttsTimeoutRef.current);
      }
      if (listeningTimeoutRef.current) {
        clearTimeout(listeningTimeoutRef.current);
      }

      isRecognitionActiveRef.current = false;
      currentStepRef.current = "idle";
      setCurrentStep("idle");
    }
  }, [isOpen, startListening]);

  /**
   * ìŒì„± ì¸ì‹ ì½œë°± ë“±ë¡
   */
  useEffect(() => {
    if (!isOpen) return;

    console.log("ğŸ¤ [Overlay] ìŒì„± ì¸ì‹ ì½œë°± ë“±ë¡");

    window.onSpeechReady = () => {
      console.log("âœ… [onSpeechReady]");
    };

    window.onSpeechStart = () => {
      console.log("ğŸ—£ï¸ [onSpeechStart]");

      if (listeningTimeoutRef.current) {
        clearTimeout(listeningTimeoutRef.current);
        listeningTimeoutRef.current = null;
      }
    };

    window.onSpeechEnd = () => {
      console.log("ğŸ›‘ [onSpeechEnd]");

      isRecognitionActiveRef.current = false;

      if (listeningTimeoutRef.current) {
        clearTimeout(listeningTimeoutRef.current);
        listeningTimeoutRef.current = null;
      }
    };

    window.onSpeechResult = async (text) => {
      console.log("âœ… [onSpeechResult]:", text);

      isRecognitionActiveRef.current = false;
      if (listeningTimeoutRef.current) {
        clearTimeout(listeningTimeoutRef.current);
        listeningTimeoutRef.current = null;
      }

      setMessages((prev) => [...prev, { role: "user", text }]);
      currentStepRef.current = "thinking";
      setCurrentStep("thinking");

      const response = await callGeminiAPI(text);
      console.log("ğŸ’¡ [AI ì‘ë‹µ]:", response);

      setMessages((prev) => [...prev, { role: "assistant", text: response }]);
      currentStepRef.current = "speaking";
      setCurrentStep("speaking");

      TemiBridge.speak(response);

      const estimatedDuration = response.length * 100;

      if (ttsTimeoutRef.current) {
        clearTimeout(ttsTimeoutRef.current);
      }

      ttsTimeoutRef.current = setTimeout(() => {
        console.log("ğŸ”„ [TTSì™„ë£Œ] ë‹¤ì‹œ ë“£ê¸°");

        currentStepRef.current = "idle";
        setCurrentStep("idle");

        setTimeout(() => {
          startListening();
        }, 500);
      }, estimatedDuration + 1000);
    };

    window.onSpeechError = (error) => {
      console.error("âŒ [onSpeechError]:", error);

      isRecognitionActiveRef.current = false;
      if (listeningTimeoutRef.current) {
        clearTimeout(listeningTimeoutRef.current);
        listeningTimeoutRef.current = null;
      }

      currentStepRef.current = "idle";
      setCurrentStep("idle");

      // âœ…âœ…âœ… Temi í™˜ê²½ì—ì„œ íŠ¹ì • ì—ëŸ¬ëŠ” ë¬´ì‹œ
      if (window.Temi) {
        if (error === "audio-capture" || error === "not-allowed") {
          console.warn("âš ï¸ Temi í™˜ê²½: ê¶Œí•œ ê´€ë ¨ ì—ëŸ¬ ë¬´ì‹œí•˜ê³  ê³„ì† ì§„í–‰");
          return; // ì—ëŸ¬ ë©”ì‹œì§€ í‘œì‹œ ì•ˆí•¨
        }

        // no_speech ì—ëŸ¬ë§Œ ì‚¬ìš©ìì—ê²Œ ì•Œë¦¼
        if (error === "no_speech") {
          TemiBridge.showToast("ìŒì„±ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ì–´ìš”. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”!");
          return;
        }
      }

      // ë¸Œë¼ìš°ì € í™˜ê²½ì—ì„œëŠ” ëª¨ë“  ì—ëŸ¬ í‘œì‹œ
      let errorMessage = "ìŒì„± ì¸ì‹ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”";

      switch (error) {
        case "no_speech":
          errorMessage = "ìŒì„±ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ì–´ìš”";
          break;
        case "no_match":
          errorMessage = "ìŒì„±ì„ ì¸ì‹í•˜ì§€ ëª»í–ˆì–´ìš”";
          break;
        case "no_permission":
          errorMessage = "ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•´ìš”";
          break;
        case "network":
        case "network_timeout":
          errorMessage = "ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”";
          break;
        case "busy":
          errorMessage = "ìŒì„± ì¸ì‹ì´ ì‚¬ìš© ì¤‘ì´ì—ìš”";
          break;
      }

      console.log(`ğŸ“¢ [ì˜¤ë¥˜] ${errorMessage}`);

      if (window.Temi) {
        TemiBridge.showToast(errorMessage);
      } else {
        console.log(`[ê°œë°œëª¨ë“œ] ${errorMessage}`);
      }

      // no_speech, busy ì™¸ì—ëŠ” ì¬ì‹œë„
      if (error !== "no_speech" && error !== "busy") {
        setTimeout(() => {
          startListening();
        }, 2000);
      }
    };

    return () => {
      console.log("ğŸ§¹ [Overlay] ì½œë°± í•´ì œ");

      if (ttsTimeoutRef.current) clearTimeout(ttsTimeoutRef.current);
      if (listeningTimeoutRef.current)
        clearTimeout(listeningTimeoutRef.current);

      isRecognitionActiveRef.current = false;
      currentStepRef.current = "idle";

      window.onSpeechReady = null;
      window.onSpeechStart = null;
      window.onSpeechEnd = null;
      window.onSpeechResult = null;
      window.onSpeechError = null;
    };
  }, [isOpen, startListening]);

  useEffect(() => {
    if (chatContainerRef.current) {
      chatContainerRef.current.scrollTop =
        chatContainerRef.current.scrollHeight;
    }
  }, [messages]);

  if (!isOpen) return null;

  return (
    <>
      {/* ë°˜íˆ¬ëª… ë°°ê²½ */}
      <div
        className="fixed inset-0 z-50 bg-slate-900/60 backdrop-blur-sm"
        onClick={onClose}
      ></div>

      {/* ëª¨ë‹¬ ì»¨í…ì¸  */}
      <div className="fixed inset-0 z-50 flex items-center justify-center pointer-events-none">
        <div
          className="w-[1200px] h-[900px] bg-white rounded-3xl shadow-2xl flex flex-col pointer-events-auto"
          onClick={(e) => e.stopPropagation()}
        >
          {/* í—¤ë” */}
          <div className="flex items-center justify-between px-8 py-6 border-b-2 border-gray-200 bg-gradient-to-r from-blue-500 to-blue-600 rounded-t-3xl">
            <h1 className="text-4xl font-bold text-white">
              ğŸ’¬ í…Œë¯¸ë‘ ëŒ€í™”í•˜ê¸°
            </h1>
            <button
              onClick={onClose}
              className="w-14 h-14 rounded-full bg-white/20 hover:bg-white/30 text-white flex items-center justify-center text-3xl font-bold transition-colors"
            >
              âœ•
            </button>
          </div>

          {/* ì±„íŒ… ì˜ì—­ */}
          <div
            ref={chatContainerRef}
            className="flex-1 overflow-y-auto px-8 py-6 bg-gray-50"
          >
            <div className="space-y-4">
              {messages.length === 0 && currentStep === "idle" && (
                <div className="text-center text-slate-400 text-2xl py-20">
                  ë“£ê¸°ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...
                </div>
              )}

              {messages.map((msg, idx) => (
                <div
                  key={idx}
                  className={`flex ${
                    msg.role === "user" ? "justify-end" : "justify-start"
                  }`}
                >
                  <div
                    className={`max-w-[70%] px-6 py-4 rounded-3xl shadow-md text-xl ${
                      msg.role === "user"
                        ? "bg-blue-500 text-white rounded-br-sm"
                        : "bg-white text-slate-800 rounded-bl-sm border border-gray-200"
                    }`}
                  >
                    {msg.role === "assistant" && "ğŸ¤– "}
                    {msg.text}
                  </div>
                </div>
              ))}
            </div>
          </div>

          {/* í•˜ë‹¨ ìƒíƒœ í‘œì‹œ + ì¬ì‹œì‘ ë²„íŠ¼ */}
          <div className="px-8 py-6 border-t-2 border-gray-200 bg-white rounded-b-3xl">
            <div className="flex items-center justify-between">
              {/* ìƒíƒœ í‘œì‹œ */}
              <div className="flex-1">
                {currentStep === "listening" && (
                  <div className="flex items-center gap-4 bg-red-50 px-6 py-3 rounded-full">
                    <div className="relative">
                      <div className="w-4 h-4 bg-red-500 rounded-full"></div>
                      <div className="absolute inset-0 w-4 h-4 bg-red-500 rounded-full animate-ping"></div>
                    </div>
                    <p className="text-xl font-semibold text-red-700">
                      ë“£ê³  ìˆì–´ìš”...
                    </p>
                  </div>
                )}

                {currentStep === "thinking" && (
                  <div className="flex items-center gap-4 bg-blue-50 px-6 py-3 rounded-full">
                    <div className="flex gap-2">
                      <div className="w-3 h-3 bg-blue-500 rounded-full animate-bounce"></div>
                      <div
                        className="w-3 h-3 bg-blue-500 rounded-full animate-bounce"
                        style={{ animationDelay: "0.1s" }}
                      ></div>
                      <div
                        className="w-3 h-3 bg-blue-500 rounded-full animate-bounce"
                        style={{ animationDelay: "0.2s" }}
                      ></div>
                    </div>
                    <p className="text-xl font-semibold text-blue-700">
                      ìƒê° ì¤‘...
                    </p>
                  </div>
                )}

                {currentStep === "speaking" && (
                  <div className="flex items-center gap-4 bg-green-50 px-6 py-3 rounded-full">
                    <div className="flex gap-1">
                      <div className="w-2 h-6 bg-green-500 rounded-full animate-pulse"></div>
                      <div
                        className="w-2 h-8 bg-green-500 rounded-full animate-pulse"
                        style={{ animationDelay: "0.1s" }}
                      ></div>
                      <div
                        className="w-2 h-6 bg-green-500 rounded-full animate-pulse"
                        style={{ animationDelay: "0.2s" }}
                      ></div>
                      <div
                        className="w-2 h-8 bg-green-500 rounded-full animate-pulse"
                        style={{ animationDelay: "0.3s" }}
                      ></div>
                    </div>
                    <p className="text-xl font-semibold text-green-700">
                      ë§í•˜ëŠ” ì¤‘...
                    </p>
                  </div>
                )}

                {currentStep === "idle" && (
                  <div className="flex items-center gap-4 bg-gray-100 px-6 py-3 rounded-full">
                    <p className="text-xl text-slate-600">ëŒ€ê¸° ì¤‘...</p>
                  </div>
                )}
              </div>

              {/* ì¬ì‹œì‘ ë²„íŠ¼ (idle ìƒíƒœì¼ ë•Œë§Œ) */}
              {currentStep === "idle" && (
                <button
                  onClick={startListening}
                  className="ml-4 px-8 py-4 bg-gradient-to-r from-blue-500 to-blue-600 hover:from-blue-600 hover:to-blue-700 text-white rounded-full font-bold text-xl shadow-lg transition-all hover:scale-105 flex items-center gap-3"
                >
                  <svg
                    className="w-6 h-6"
                    fill="currentColor"
                    viewBox="0 0 20 20"
                  >
                    <path
                      fillRule="evenodd"
                      d="M7 4a3 3 0 016 0v4a3 3 0 11-6 0V4zm4 10.93A7.001 7.001 0 0017 8a1 1 0 10-2 0A5 5 0 015 8a1 1 0 00-2 0 7.001 7.001 0 006 6.93V17H6a1 1 0 100 2h8a1 1 0 100-2h-3v-2.07z"
                      clipRule="evenodd"
                    />
                  </svg>
                  ë‹¤ì‹œ ë§í•˜ê¸°
                </button>
              )}
            </div>
          </div>
        </div>
      </div>
    </>
  );
}
