    // web/src/hooks/useVoiceChat.js
    import { useState, useEffect, useCallback, useRef } from "react";
    import { TemiBridge } from "../services/temiBridge";
    import { callGeminiAPI } from "../utils/geminiAPI";

    /**
     * ìŒì„± ì±„íŒ… ê¸°ëŠ¥ì„ ê´€ë¦¬í•˜ëŠ” ì»¤ìŠ¤í…€ í›…
     * ë“£ê¸° â†’ ìƒê° â†’ ë§í•˜ê¸° â†’ ë“£ê¸° ìˆœí™˜
     */
    export default function useVoiceChat(isActive) {
    // í˜„ìž¬ ë‹¨ê³„: 'listening' | 'thinking' | 'speaking' | 'idle'
    const [currentStep, setCurrentStep] = useState("idle");

    // í˜„ìž¬ ëŒ€í™” ìŒ (ì‚¬ìš©ìž ë©”ì‹œì§€ + í…Œë¯¸ ì‘ë‹µ)
    const [currentUserMessage, setCurrentUserMessage] = useState("");
    const [currentAssistantMessage, setCurrentAssistantMessage] = useState("");

    // refë¡œ ìƒíƒœ ì¶”ì  (ì¦‰ê° ë°˜ì˜)
    const isRecognitionActiveRef = useRef(false);
    const ttsTimeoutRef = useRef(null);
    const listeningTimeoutRef = useRef(null); // âœ… ë“£ê¸° íƒ€ìž„ì•„ì›ƒ ì¶”ê°€
    const currentStepRef = useRef("idle");
    const onAutoStopCallback = useRef(null); // âœ… ìžë™ ì¢…ë£Œ ì½œë°±

    /**
     * ìŒì„± ì¸ì‹ ì‹œìž‘ í•¨ìˆ˜ (ì•ˆì „í•œ ë²„ì „)
     */
    const startListening = useCallback(() => {
        console.log("ðŸŽ¤ [startListening] ì‹œë„");

        // âœ… ì´ë¯¸ í™œì„±í™”ë˜ì–´ ìžˆìœ¼ë©´ ë¬´ì‹œ
        if (isRecognitionActiveRef.current) {
        console.log("âš ï¸ [startListening] ì´ë¯¸ ì¸ì‹ ì„¸ì…˜ í™œì„±í™”ë¨, ë¬´ì‹œ");
        return;
        }

        // âœ… ë‹¤ë¥¸ ë‹¨ê³„ ì§„í–‰ ì¤‘ì´ë©´ ë¬´ì‹œ
        if (currentStepRef.current !== "idle") {
        console.log(
            `âš ï¸ [startListening] í˜„ìž¬ ${currentStepRef.current} ë‹¨ê³„, ë¬´ì‹œ`
        );
        return;
        }

        console.log("âœ… [startListening] ìŒì„± ì¸ì‹ ì‹œìž‘");

        // âœ… ì´ì „ ë©”ì‹œì§€ í´ë¦¬ì–´ (ìƒˆë¡œìš´ ìˆœí™˜ ì‹œìž‘)
        setCurrentUserMessage("");
        setCurrentAssistantMessage("");

        isRecognitionActiveRef.current = true;
        currentStepRef.current = "listening";
        setCurrentStep("listening");

        try {
        TemiBridge.startSpeechRecognition();

        // âœ… 8ì´ˆ íƒ€ìž„ì•„ì›ƒ ì„¤ì •
        if (listeningTimeoutRef.current) {
            clearTimeout(listeningTimeoutRef.current);
        }

        listeningTimeoutRef.current = setTimeout(() => {
            console.log("â° [Timeout] 8ì´ˆ ë™ì•ˆ ìŒì„± ê°ì§€ ì•ˆë¨, ìžë™ ì¢…ë£Œ");

            isRecognitionActiveRef.current = false;
            currentStepRef.current = "idle";
            setCurrentStep("idle");
            setCurrentUserMessage("");
            setCurrentAssistantMessage("");

            // âœ… ìŒì„± ì¸ì‹ ì¤‘ì§€
            TemiBridge.stopSpeechRecognition();

            // âœ… ìžë™ ì¢…ë£Œ ì½œë°± í˜¸ì¶œ (PageLayoutì—ì„œ isChatActiveë¥¼ falseë¡œ)
            if (onAutoStopCallback.current) {
            onAutoStopCallback.current();
            }

            TemiBridge.showToast("ìŒì„±ì´ ê°ì§€ë˜ì§€ ì•Šì•„ ëŒ€í™”ê°€ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤");
        }, 8000);
        } catch (error) {
        console.error("âŒ [startListening] ì‹¤íŒ¨:", error);
        isRecognitionActiveRef.current = false;
        currentStepRef.current = "idle";
        setCurrentStep("idle");

        // íƒ€ìž„ì•„ì›ƒ ì •ë¦¬
        if (listeningTimeoutRef.current) {
            clearTimeout(listeningTimeoutRef.current);
        }
        }
    }, []);

    /**
     * ìŒì„± ì¸ì‹ ì½œë°± ë“±ë¡
     */
    useEffect(() => {
        if (!isActive) {
        // ë¹„í™œì„±í™” ì‹œ ëª¨ë“  ìƒíƒœ ì´ˆê¸°í™”
        if (ttsTimeoutRef.current) {
            clearTimeout(ttsTimeoutRef.current);
        }
        if (listeningTimeoutRef.current) {
            clearTimeout(listeningTimeoutRef.current);
        }
        isRecognitionActiveRef.current = false;
        currentStepRef.current = "idle";
        setCurrentStep("idle");
        setCurrentUserMessage("");
        setCurrentAssistantMessage("");
        return;
        }

        console.log("ðŸŽ¤ [useEffect] ìŒì„± ì¸ì‹ ì½œë°± ë“±ë¡");

        // ===== ìŒì„± ì¸ì‹ ì¤€ë¹„ ì™„ë£Œ =====
        window.onSpeechReady = () => {
        console.log("âœ… [onSpeechReady] ìŒì„± ì¸ì‹ ì¤€ë¹„ ì™„ë£Œ");
        };

        // ===== ìŒì„± ê°ì§€ ì‹œìž‘ =====
        window.onSpeechStart = () => {
        console.log("ðŸ—£ï¸ [onSpeechStart] ìŒì„± ê°ì§€ ì‹œìž‘");

        // âœ… ìŒì„± ê°ì§€ë˜ë©´ íƒ€ìž„ì•„ì›ƒ ì·¨ì†Œ
        if (listeningTimeoutRef.current) {
            console.log("âœ… [onSpeechStart] íƒ€ìž„ì•„ì›ƒ ì·¨ì†Œ");
            clearTimeout(listeningTimeoutRef.current);
            listeningTimeoutRef.current = null;
        }
        };

        // ===== ìŒì„± ìž…ë ¥ ì¢…ë£Œ =====
        window.onSpeechEnd = () => {
        console.log("ðŸ›‘ [onSpeechEnd] ìŒì„± ìž…ë ¥ ì¢…ë£Œ");

        // âœ… ì„¸ì…˜ ì¢…ë£Œ í‘œì‹œ (ì¦‰ì‹œ)
        isRecognitionActiveRef.current = false;

        // âœ… íƒ€ìž„ì•„ì›ƒ ì •ë¦¬
        if (listeningTimeoutRef.current) {
            clearTimeout(listeningTimeoutRef.current);
            listeningTimeoutRef.current = null;
        }
        };

        // ===== ìŒì„± ì¸ì‹ ê²°ê³¼ ì²˜ë¦¬ =====
        window.onSpeechResult = async (text) => {
        console.log("âœ… [onSpeechResult] ì¸ì‹ ê²°ê³¼:", text);

        // âœ… ì¦‰ì‹œ ì„¸ì…˜ ì¢…ë£Œ + íƒ€ìž„ì•„ì›ƒ ì •ë¦¬
        isRecognitionActiveRef.current = false;
        if (listeningTimeoutRef.current) {
            clearTimeout(listeningTimeoutRef.current);
            listeningTimeoutRef.current = null;
        }

        // 1ï¸âƒ£ ì‚¬ìš©ìž ë©”ì‹œì§€ í‘œì‹œ + ìƒê° ë‹¨ê³„ë¡œ ì „í™˜
        setCurrentUserMessage(text);
        currentStepRef.current = "thinking";
        setCurrentStep("thinking");

        // 2ï¸âƒ£ Gemini API í˜¸ì¶œ
        const response = await callGeminiAPI(text);
        console.log("ðŸ’¡ [onSpeechResult] AI ì‘ë‹µ:", response);

        // 3ï¸âƒ£ í…Œë¯¸ ì‘ë‹µ í‘œì‹œ + ë§í•˜ê¸° ë‹¨ê³„ë¡œ ì „í™˜
        setCurrentAssistantMessage(response);
        currentStepRef.current = "speaking";
        setCurrentStep("speaking");

        // 4ï¸âƒ£ TTS ì‹¤í–‰
        TemiBridge.speak(response);

        // 5ï¸âƒ£ TTS ì™„ë£Œ ëŒ€ê¸° í›„ ë‹¤ì‹œ ë“£ê¸°
        const estimatedDuration = response.length * 100;

        if (ttsTimeoutRef.current) {
            clearTimeout(ttsTimeoutRef.current);
        }

        ttsTimeoutRef.current = setTimeout(() => {
            console.log("ðŸ”„ [TTSì™„ë£Œ] ë‹¤ì‹œ ë“£ê¸° ì‹œìž‘");

            currentStepRef.current = "idle";
            setCurrentStep("idle");

            // âœ… ì—¬ì „ížˆ í™œì„±í™” ìƒíƒœë©´ ë‹¤ìŒ ìˆœí™˜ ì‹œìž‘
            if (isActive) {
            setTimeout(() => {
                startListening();
            }, 500); // âœ… ì•ˆì „ì„ ìœ„í•œ 500ms ë”œë ˆì´
            }
        }, estimatedDuration + 1000); // âœ… ì—¬ìœ ì‹œê°„ 1ì´ˆ
        };

        // ===== ìŒì„± ì¸ì‹ ì˜¤ë¥˜ ì²˜ë¦¬ =====
        window.onSpeechError = (error) => {
        console.error("âŒ [onSpeechError] ì˜¤ë¥˜:", error);

        // âœ… ì¦‰ì‹œ ì„¸ì…˜ ì¢…ë£Œ + íƒ€ìž„ì•„ì›ƒ ì •ë¦¬
        isRecognitionActiveRef.current = false;
        if (listeningTimeoutRef.current) {
            clearTimeout(listeningTimeoutRef.current);
            listeningTimeoutRef.current = null;
        }

        currentStepRef.current = "idle";
        setCurrentStep("idle");

        let errorMessage = "ìŒì„± ì¸ì‹ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”";

        switch (error) {
            case "no_speech":
            errorMessage = "ìŒì„±ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ì–´ìš”";
            break;
            case "no_match":
            errorMessage = "ìŒì„±ì„ ì¸ì‹í•˜ì§€ ëª»í–ˆì–´ìš”";
            break;
            case "no_permission":
            errorMessage = "ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•´ìš”";
            break;
            case "network":
            case "network_timeout":
            errorMessage = "ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”";
            break;
            case "busy":
            errorMessage = "ìŒì„± ì¸ì‹ì´ ì‚¬ìš© ì¤‘ì´ì—ìš”";
            break;
        }

        console.log(`ðŸ“¢ [onSpeechError] ${errorMessage}`);

        if (window.Temi) {
            TemiBridge.showToast(errorMessage);
        } else {
            console.log(`[ê°œë°œëª¨ë“œ] ${errorMessage}`);
        }

        // âœ… no_speech, busy ì˜¤ë¥˜ë©´ ìžë™ ì¢…ë£Œ
        if (error === "no_speech" || error === "busy") {
            console.log("ðŸ”´ [onSpeechError] ìžë™ ì¢…ë£Œ");
            if (onAutoStopCallback.current) {
            onAutoStopCallback.current();
            }
            return;
        }

        // âœ… ë‹¤ë¥¸ ì˜¤ë¥˜ëŠ” ìž¬ì‹œë„
        if (isActive) {
            console.log("ðŸ”„ [onSpeechError] 2ì´ˆ í›„ ìž¬ì‹œë„");
            setTimeout(() => {
            startListening();
            }, 2000);
        }
        };

        // cleanup
        return () => {
        console.log("ðŸ§¹ [cleanup] ìŒì„± ì¸ì‹ ì½œë°± í•´ì œ");

        if (ttsTimeoutRef.current) {
            clearTimeout(ttsTimeoutRef.current);
        }

        if (listeningTimeoutRef.current) {
            clearTimeout(listeningTimeoutRef.current);
        }

        isRecognitionActiveRef.current = false;
        currentStepRef.current = "idle";

        window.onSpeechReady = null;
        window.onSpeechStart = null;
        window.onSpeechEnd = null;
        window.onSpeechResult = null;
        window.onSpeechError = null;
        };
    }, [isActive, startListening]);

    /**
     * ìƒíƒœ ì´ˆê¸°í™”
     */
    const reset = useCallback(() => {
        if (ttsTimeoutRef.current) {
        clearTimeout(ttsTimeoutRef.current);
        }

        if (listeningTimeoutRef.current) {
        clearTimeout(listeningTimeoutRef.current);
        }

        isRecognitionActiveRef.current = false;
        currentStepRef.current = "idle";
        setCurrentStep("idle");
        setCurrentUserMessage("");
        setCurrentAssistantMessage("");
    }, []);

    /**
     * ìžë™ ì¢…ë£Œ ì½œë°± ë“±ë¡
     */
    const setOnAutoStop = useCallback((callback) => {
        onAutoStopCallback.current = callback;
    }, []);

    return {
        currentStep,
        currentUserMessage,
        currentAssistantMessage,
        startListening,
        reset,
        setOnAutoStop, // âœ… ì¶”ê°€
    };
    }
